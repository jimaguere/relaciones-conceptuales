{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Servicio import Service\n",
    "from sklearn.preprocessing import scale\n",
    "import sqlalchemy as sa\n",
    "s=Service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from time import time  # To time our operations\n",
    "import re  # For preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_documento</th>\n",
       "      <th>resumen</th>\n",
       "      <th>grupo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4249</td>\n",
       "      <td>octubre emanada honorable consejo directivo un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>juridico efectos codigo penal practica judicia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4610</td>\n",
       "      <td>determinan parámetros ejercer interventores su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2258</td>\n",
       "      <td>isabel goyes moreno universidad nariño investi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2861</td>\n",
       "      <td>ciudad pasto francisco edmundo obando universi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>2517</td>\n",
       "      <td>marco teorico acondicionamiento peces transpor...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8072</th>\n",
       "      <td>7051</td>\n",
       "      <td>evaluación crecimiento poblacional diatomea th...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>2433</td>\n",
       "      <td>efecto dióxido carbono concentraciones producc...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>7066</td>\n",
       "      <td>elaboración galantina remplazando zanahoria da...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>658</td>\n",
       "      <td>octubre emanado honorable consejo directivo un...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8076 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_documento                                            resumen  grupo\n",
       "0             4249  octubre emanada honorable consejo directivo un...      0\n",
       "1               21  juridico efectos codigo penal practica judicia...      0\n",
       "2             4610  determinan parámetros ejercer interventores su...      0\n",
       "3             2258  isabel goyes moreno universidad nariño investi...      0\n",
       "4             2861  ciudad pasto francisco edmundo obando universi...      0\n",
       "...            ...                                                ...    ...\n",
       "8071          2517  marco teorico acondicionamiento peces transpor...     31\n",
       "8072          7051  evaluación crecimiento poblacional diatomea th...     31\n",
       "8073          2433  efecto dióxido carbono concentraciones producc...     31\n",
       "8074          7066  elaboración galantina remplazando zanahoria da...     31\n",
       "8075           658  octubre emanado honorable consejo directivo un...     31\n",
       "\n",
       "[8076 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"select d.id_documento,d.resumen,gr.grupo from documento d  join documentos_grupo_def gr on gr.id_documento=d.id_documento join documentos_doc2_vec dv on dv.id_documento =d.id_documento order by grupo;\"\n",
    "df=pd.read_sql(sa.text(sql),s.dao.engine)\n",
    "s.dao.engine.dispose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('es_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JBARCO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JBARCO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "spacy.cli.download(\"es_core_news_sm\")\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))\n",
    "\n",
    "def lexeme_tokenize(text):\n",
    "    text=text.lower()\n",
    "    doc = nlp(text)\n",
    "    lemmas = [t.lemma_.lower() for t in doc if not t.is_punct | t.is_stop]\n",
    "    words = [t.lower() for t in lemmas if len(t) > 3 and t.isalpha()]\n",
    "    return words \n",
    "\n",
    "def stem_tokenize(text, stemmer):\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    tokens=word_tokenize(text)\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        if item not in spanish_stopwords:\n",
    "            stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modelo_tf_idf = TfidfVectorizer(max_df=0.7, min_df=0.1,\n",
    "                     lowercase=True,\n",
    "                     ngram_range = (1,1),\n",
    "                     analyzer = 'word',\n",
    "                     tokenizer = lexeme_tokenize,              \n",
    "                     max_features=7000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_tf = modelo_tf_idf.fit_transform(df['resumen'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estructurado_tf_idf=pd.DataFrame(matrix_tf.toarray(),columns=modelo_tf_idf.get_feature_names())\n",
    "df_estructurado_tf_idf.to_csv('.\\\\Datos\\\\tesis_estructurada_7000.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abajar</th>\n",
       "      <th>abandonar</th>\n",
       "      <th>abarcar</th>\n",
       "      <th>abastecer</th>\n",
       "      <th>abastecimiento</th>\n",
       "      <th>abonar</th>\n",
       "      <th>abordar</th>\n",
       "      <th>abril</th>\n",
       "      <th>abrir</th>\n",
       "      <th>absoluto</th>\n",
       "      <th>...</th>\n",
       "      <th>étnico</th>\n",
       "      <th>éxito</th>\n",
       "      <th>índice</th>\n",
       "      <th>índole</th>\n",
       "      <th>ítem</th>\n",
       "      <th>óptico</th>\n",
       "      <th>órgano</th>\n",
       "      <th>únicamente</th>\n",
       "      <th>único</th>\n",
       "      <th>útil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117695</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.002907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abajar  abandonar   abarcar  abastecer  abastecimiento  abonar   abordar  \\\n",
       "0     0.0   0.001839  0.013028        0.0             0.0     0.0  0.000000   \n",
       "1     0.0   0.006691  0.009478        0.0             0.0     0.0  0.010570   \n",
       "2     0.0   0.000000  0.000000        0.0             0.0     0.0  0.002665   \n",
       "3     0.0   0.000000  0.003197        0.0             0.0     0.0  0.000000   \n",
       "4     0.0   0.000000  0.000000        0.0             0.0     0.0  0.003129   \n",
       "\n",
       "      abril     abrir  absoluto  ...    étnico     éxito  índice    índole  \\\n",
       "0  0.003424  0.004945  0.003869  ...  0.117695  0.001511     0.0  0.006618   \n",
       "1  0.003737  0.000900  0.005630  ...  0.000000  0.000000     0.0  0.001605   \n",
       "2  0.002827  0.000000  0.000000  ...  0.000000  0.000000     0.0  0.000000   \n",
       "3  0.013445  0.002427  0.015193  ...  0.000000  0.000000     0.0  0.008661   \n",
       "4  0.013277  0.002397  0.000000  ...  0.000000  0.000000     0.0  0.000000   \n",
       "\n",
       "   ítem    óptico    órgano  únicamente     único      útil  \n",
       "0   0.0  0.004819  0.016193    0.001410  0.005909  0.002907  \n",
       "1   0.0  0.003506  0.008836    0.010262  0.008599  0.001058  \n",
       "2   0.0  0.000000  0.003342    0.000000  0.011706  0.000000  \n",
       "3   0.0  0.000000  0.007947    0.000000  0.006960  0.000000  \n",
       "4   0.0  0.000000  0.000000    0.008203  0.006873  0.000000  \n",
       "\n",
       "[5 rows x 3112 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estructurado_tf_idf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
